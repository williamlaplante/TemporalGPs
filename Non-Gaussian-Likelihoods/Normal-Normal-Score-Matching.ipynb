{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Prior, Normal Likelihood - Mean and Covariance Unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Normal($\\theta$) with $ \\theta = (\\mu, \\sigma^2)$ is reparametrized according to the exponential family's natural parameters:\n",
    "\n",
    "$ \\eta(\\theta) = \\eta(\\mu, \\sigma^2) = (\\mu / \\sigma^2, -1 / 2\\sigma^2) = (\\eta_1, \\eta_2) $\n",
    "\n",
    "$ \\eta^{-1}(\\eta_1, \\eta_2) = (-\\eta_1 / 2\\eta_2, -1 / 2\\eta_2)$\n",
    "\n",
    "Therefore, the prior is on $\\eta$ and of the form\n",
    "\n",
    "$ \\pi (\\eta; \\alpha, R) \\propto \\exp \\left(-\\frac{1}{2}(\\eta - \\alpha)^T R^{-1}(\\eta - \\alpha)   \\right) $,\n",
    "\n",
    "where we need to specify $\\alpha$ and $R$, the prior mean and prior covariance (mean on $\\eta$, not $\\theta$!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful functions\n",
    "\n",
    "def eta(mu, sigma2):\n",
    "    \"\"\"computes eta(theta) = eta(mu, sigma2)\"\"\"\n",
    "    return np.array([[mu/sigma2, -1/(2*sigma2)]]).T\n",
    "\n",
    "def eta_jac(mu, sigma2):\n",
    "    return np.array([ [1/sigma2, -mu/(sigma2**2)],\n",
    "                      [0.         , 1/(2*sigma2**2)] ]\n",
    "                    )\n",
    "\n",
    "def eta_inv(eta1, eta2):\n",
    "    \"\"\"recovers mu, sigma^2 (**NOT** sigma only, its square)\"\"\"\n",
    "    return np.array([-eta1/(2*eta2), -1/(2*eta2) ])\n",
    "\n",
    "def eta_inv_jac(eta1, eta2):\n",
    "    \"\"\"compute the jacobian of eta^{-1}(eta1, eta2)\"\"\"\n",
    "    return np.array([ [-1/(2*eta2), eta1/(2*eta2**2)],\n",
    "                        [0.         , 1/(2*eta2**2)] ]\n",
    "                    )\n",
    "\n",
    "def log_normal_density(x, mu, sigma2):\n",
    "    return 1 / np.sqrt(x**2 * sigma2 * 2 * np.pi) * np.exp( (-1/2) * (np.log(x) - mu)**2 / sigma2 )\n",
    "\n",
    "def normal_density(x, mu, sigma2):\n",
    "    return 1 / np.sqrt(sigma2 * 2 * np.pi) * np.exp( (-1/2) * (x - mu)**2 / sigma2 )\n",
    "\n",
    "def MV_normal(x, mu, Sigma):\n",
    "    return np.exp((-1/2) * (x - mu).T @ np.linalg.inv(Sigma) @ (x - mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normal():\n",
    "    def __init__(self, eta_prior_mean, eta_prior_cov):\n",
    "        self.eta_prior_mean = eta_prior_mean #prior on eta\n",
    "        self.eta_prior_cov = eta_prior_cov #prior on cov of eta\n",
    "        self.num_params = eta_prior_mean.size\n",
    "\n",
    "        self.dr_ = lambda x : np.array([[1., 2 * x]])\n",
    "        self.db_ = lambda x : 0.\n",
    "        self.ddr_ = lambda x : np.array([[0., 2.]])\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def posterior(self, data):\n",
    "        assert data.ndim == 1, \"Data must be 1-dimensional\"\n",
    "\n",
    "        Lambda = np.zeros((self.num_params, self.num_params), dtype=float)\n",
    "        Nu = np.zeros(self.eta_prior_mean.shape)\n",
    "\n",
    "        T = len(data)\n",
    "\n",
    "        for x in data:\n",
    "            Lambda += (1/T) * self.dr_(x).T @ self.dr_(x)\n",
    "            Nu += (2/T) * (self.dr_(x).T * self.db_(x) + self.ddr_(x).T)\n",
    "\n",
    "        eta_post_cov = np.linalg.inv(np.linalg.inv(self.eta_prior_cov) + 2 * T * Lambda)\n",
    "        eta_post_mean = eta_post_cov @ (np.linalg.inv(self.eta_prior_cov) @ self.eta_prior_mean - T * Nu)\n",
    "\n",
    "        return eta_post_mean.flatten(), eta_post_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive frequentist estimate (mean, var)             :  [1.0418656108741395, 0.49775504341531646]\n",
      "theta from Normal-Normal (known var) (mean, var)   :  [1.03670536 0.49775504]\n",
      "\n",
      "theta from Normal-Normal (unknown var) (mean, var) :  [1.03926744 0.50294725]\n",
      "formula                                            :  1.0392674422684685\n",
      "theta (true)                                       :  [1.   0.49]\n"
     ]
    }
   ],
   "source": [
    "#fix a random seed for experimental purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "#the \"true parameters\", and the generated data\n",
    "mu = 1.0\n",
    "sigma2 = 0.7**2\n",
    "\n",
    "size = 100\n",
    "data = np.random.normal(loc=mu, scale=np.sqrt(sigma2), size=size)\n",
    "\n",
    "#Setting the prior on theta = (mu, sigma2)\n",
    "mu_prior, sigma2_prior = 0.0, 1.0\n",
    "alpha, beta = 2, 1\n",
    "theta_prior_mean = np.array([mu_prior, sigma2_prior])\n",
    "theta_prior_cov = np.array([[alpha, 0], [0, beta]])\n",
    "\n",
    "#converting the prior mu and sigma2 to natural parameters\n",
    "\n",
    "eta_prior_mean = eta(*theta_prior_mean)\n",
    "eta_prior_cov = eta_jac(mu_prior, sigma2_prior) @ theta_prior_cov @ eta_jac(mu_prior, sigma2_prior).T\n",
    "\n",
    "#instantiating the LogNormal class and obtaining the posterior mean and covariance for the r.v. \\eta | data \n",
    "norm = Normal(eta_prior_mean=eta_prior_mean, eta_prior_cov=eta_prior_cov)\n",
    "eta_post_mean, eta_post_cov = norm.posterior(data=data)\n",
    "\n",
    "#converting back from eta to mu, sigma2, and obtaining the mean and covariance for mu and sigma2\n",
    "theta_post_mean = eta_inv(*eta_post_mean)\n",
    "theta_post_cov = eta_inv_jac(*eta_post_mean) @ eta_post_cov @ eta_inv_jac(*eta_post_mean).T\n",
    "\n",
    "NN_sigma2 = data.var() #Normal-Normal likelihood covariance (known)\n",
    "NN_theta_post = (1 / (1/sigma2_prior + size/NN_sigma2) ) * (mu_prior/sigma2_prior + data.sum()/NN_sigma2)\n",
    "\n",
    "\n",
    "theta_post_mean_formula = data.mean() / (1 + sigma2_prior**2 / (2 * size * alpha))\n",
    "\n",
    "print(\"naive frequentist estimate (mean, var)             : \", [data.mean(), data.var()])\n",
    "print(\"theta from Normal-Normal (known var) (mean, var)   : \", np.array([NN_theta_post, NN_sigma2]))\n",
    "print()\n",
    "print(\"theta from Normal-Normal (unknown var) (mean, var) : \", theta_post_mean)\n",
    "print(\"formula                                            : \", theta_post_mean_formula)\n",
    "print(\"theta (true)                                       : \", np.array([mu, sigma2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TemporalGPs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
